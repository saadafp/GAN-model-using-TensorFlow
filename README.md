# GAN-model-using-TensorFlow
In this repo, I will use GAN(Generative Adversarial Network) on Anime_image dataset.
GAN is short form of Generative Adversarial Network and a deep learning architecture. GAN consists of 2 parts, Discriminator and Generator.
The Generator tries to creat fake images and fool the Discriminator, and Discriminator tries to distinguish the images and label them as fake(0) or real(1).

This zero-sum game continuees until the Generator can no longer creat images which fools the Discriminator and the Discriminator cannot be fooled.

There are different types of GAN Models but we are using DCGAN which is the short form of Deep Convolutional GAN.



**What is Discriminator ?**

The Discriminator is a Neural Network model which tries to distinguish the real images from fake images(generated by Generator) and label them as fake(0) or real(1).

Notes :

1.The image size is (64,64), so the input_shape of first conv2d layer should be (64,64,3).

2.The output of Discriminator is either a 0(fake) or 1(real).

3.Using "same" as padding ensures us that the output dimension is not going to change.

4.In the Discriminator function, all activations should be "LeakyReLU", exept the last layer which should be "sigmoid"

5.The last layer is using "sigmoid" as activation function to create a binary output, which real images are labeled as 1 and the fake ones are labeled as 0.

6.The Discriminator downsamples the input shape.


**What is Generator ?**

The Generator tries to creat fake images and fool the Discriminator, and Discriminator tries to distinguish the images and label them as fake(0) or real(1).

Notes :

1.The latent space is an arbitrarily defined vector space of Gaussian-distributed values and here I consider 100 as latent_dim.

2.Also units in Dense layer can be (4,4,256) (so it has 4096 nodes)---> 256 versions of 4*4 images.

3.Using "same" as padding ensures us that the output dimension is not going to change.

4.The output shape will be (None, 64, 64, 3) just like the input image(real image) of Discriminator.

5.In Generator, we can use Upsampling or Conv2DTranspose layer to upsample the input.

**This dataset has 63,632 "high-quality" anime faces.**
The source of the dataset is from kaggle : https://www.kaggle.com/datasets/splcher/animefacedataset
